<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png"/><link rel="manifest" href="/favicon/site.webmanifest"/><link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#000000"/><link rel="shortcut icon" href="/favicon/favicon.ico"/><meta name="msapplication-TileColor" content="#000000"/><meta name="msapplication-config" content="/favicon/browserconfig.xml"/><meta name="theme-color" content="#000"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><meta name="description" content="The Stack Journal | Your tech source; women by women."/><meta property="og:image" content="https://pbs.twimg.com/profile_images/1717871792323264512/tVsGvCry_400x400.jpg"/><title>Unbiased: How Can AI Be Designed to Be Unbiased Towards Black Women | The Stack Journal | Your tech source; women by women</title><meta property="og:image" content="https://wp.thestackjournal.com/wp-content/uploads/2024/03/oc0413wkhxjg7dbcnpnk.jpeg"/><meta name="next-head-count" content="16"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/cd23bc4cf6bf232d.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/cd23bc4cf6bf232d.css" crossorigin="" data-n-g=""/><link rel="preload" href="/_next/static/css/8600ba00a31e87dd.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/8600ba00a31e87dd.css" crossorigin="" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee7e63bc15b31913.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-5429a50ba5373c56.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-e24b4219d45d8163.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-35e996cc529f89c1.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/247-f79fefcd52c96378.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/607-55fc342faa3a367b.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/593-d92d2f977447e757.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-44961f611194ebdf.js" defer="" crossorigin=""></script><script src="/_next/static/L5IHP0rbpf_nxdR51peX3/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/L5IHP0rbpf_nxdR51peX3/_ssgManifest.js" defer="" crossorigin=""></script><style data-href="https://fonts.googleapis.com/css2?family=Mulish&display=swap">@font-face{font-family:'Mulish';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mulish/v13/1Ptyg83HX_SGhgqO0yLcmjzUAuWexZNRwaM.woff) format('woff')}@font-face{font-family:'Mulish';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mulish/v13/1Ptyg83HX_SGhgqO0yLcmjzUAuWexZNR8aqvHZ47LTdNwPak.woff) format('woff');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Mulish';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mulish/v13/1Ptyg83HX_SGhgqO0yLcmjzUAuWexZNR8aOvHZ47LTdNwPak.woff) format('woff');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Mulish';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mulish/v13/1Ptyg83HX_SGhgqO0yLcmjzUAuWexZNR8aivHZ47LTdNwPak.woff) format('woff');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Mulish';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mulish/v13/1Ptyg83HX_SGhgqO0yLcmjzUAuWexZNR8amvHZ47LTdNwPak.woff) format('woff');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Mulish';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/mulish/v13/1Ptyg83HX_SGhgqO0yLcmjzUAuWexZNR8aevHZ47LTdNwA.woff) format('woff');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><div class="min-h-screen"><main><div class="container mx-auto px-5 lg-px-10"><div class="hidden lg:block py-8"><div class="p-4 columns-3__"><a class="w-1/5 inline-block align-middle" href="/"><img alt="" loading="lazy" width="300" height="60" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=384&amp;q=75 1x, /_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=640&amp;q=75 2x" src="/_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=640&amp;q=75"/></a><div class="w-3/5 inline-block align-middle"><ul class="flex justify-center text-sm"><li class="mx-3"><a href="/category/startups" class="capitalize text-purple-800 border-b border-white hover:pb-1 hover:border-purple-800">Startups</a></li><li class="mx-3"><a href="/category/dear-tech-sis" class="capitalize text-purple-800 border-b border-white hover:pb-1 hover:border-purple-800">Dear Tech Sis</a></li><li class="mx-3"><a href="/category/founders" class="capitalize text-purple-800 border-b border-white hover:pb-1 hover:border-purple-800">Founders</a></li><li class="mx-3"><a href="/category/essays" class="capitalize text-purple-800 border-b border-white hover:pb-1 hover:border-purple-800">Essays</a></li><li class="mx-3"><a href="/category/news" class="capitalize text-purple-800 border-b border-white hover:pb-1 hover:border-purple-800">News</a></li><li class="relative mx-3"><a href="#" class="flex items-start text-purple-800 border-b border-white hover:pb-1 hover:border-purple-800">More<svg class="ml-1 h-6 w-6 " fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M5.293 7.293a1 1 0 0 1 1.414-1.414L10 9.586l3.293-3.293a1 1 0 1 1 1.414 1.414l-4 4a1 1 0 0 1-1.414 0l-4-4a1 1 0 0 1-.001-1.413z" clip-rule="evenodd"></path></svg></a><div class="flex absolute z-10 bg-white mt-1 border rounded-base shadow-lg hidden"><div class="flex justify-between px-8 py-4"><ul class="flex flex-col text-nowrap"><li class="my-2"><a href="/category/awards" class="border-b border-white hover:pb-1 hover:border-purple-800">Awards</a></li><li class="my-2"><a href="/category/events" class="border-b border-white hover:pb-1 hover:border-purple-800">Events</a></li><li class="my-2"><a href="/category/opportunities" class="border-b border-white hover:pb-1 hover:border-purple-800">Opportunities</a></li><li class="my-2"><a href="/category/industry-report" class="border-b border-white hover:pb-1 hover:border-purple-800">Industry Report</a></li></ul><img src="https://via.placeholder.com/300x75" alt="placeholder" class="hidden ml-4 pl-8 border-l border-gray-300"/></div></div></li></ul></div><div class="w-1/5 hidden align-middle">search bar </div></div></div><div class="lg:hidden my-3"><div class="flex items-center justify-between"><a href="#" class="text-2xl font-bold"><img alt="" loading="lazy" width="180" height="50" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=256&amp;q=75 1x, /_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=384&amp;q=75 2x" src="/_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=384&amp;q=75"/></a><button class="flex items-center px-3 py-2 rounded hover:bg-gray-200"><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></div><article><div class="" style="background-image:linear-gradient(0, rgb(0 0 0 / 50%), rgb(0 0 0 / 50%)), url(https://wp.thestackjournal.com/wp-content/uploads/2024/03/oc0413wkhxjg7dbcnpnk.jpeg);background-repeat:no-repeat;background-size:cover;background-position:center"><div class="lg:w-3/5 lg:max-h-[600px] mx-auto p-12 lg:px-0 lg:py-48 text-white text-center"><div class="my-4"><a href="/category/dear-tech-sis"><span style="outline:solid 1px rgb(20 184 166);color:rgb(20 184 166)" class="capitalize rounded-full px-6 py-3"> <!-- -->Dear Tech Sis<!-- --> </span></a></div><h1 class="text-lg lg:text-6xl font-semibold leading-snug">Unbiased: How Can AI Be Designed to Be Unbiased Towards Black Women</h1><div class="my-4 text-sm lg:text-lg"><span class="font-semi-bold">Iyanuoluwa Adenle</span><span class="mx-2"> | </span><time dateTime="2022-06-11T12:00:00">June	11, 2022</time></div></div></div><div class="container lg:w-4/5 mx-auto my-4 lg:my-12"><div class="lg:flex items-start gap-16 px-4 lg:px-0"><div><div class="post-body_content__ye_eq">
<p>Artificial Intelligence (AI) has become even more popular in recent years. Governmental bodies, large organizations, and small online businesses are all using AI to make smart business decisions. AI is a type of technology that enables computers to learn on their own, without being programmed with the help of advanced algorithms.&nbsp;</p>



<p>People often assume that AI is neutral, except they aren’t. The problem with AI today is the algorithm. By design, algorithms are built using past data sets in order to learn from them. If the past was biased towards white males, then this will lead to biased results. This is known as ‘algorithmic bias’ or ‘machine learning bias’. Algorithms can be trained on an inherently limited set of data, and this means that the gender and race gap in the data sets mess with the algorithms. Machines learn the data that it is being fed and if the data recommended to the machine is already biased, AI can be programmed to be racist, sexist or prejudiced.</p>



<p>When we factor in&nbsp;<a href="https://time.com/5520558/artificial-intelligence-racial-gender-bias/">racial and gender bias</a>&nbsp;that is being recommended into the systems, therefore influencing the algorithms, it becomes clear that because the people aren’t diverse enough in their thinking and tastes, our algorithms are biased as well. It is important that the problem is fixed by having diverse teams building these kinds of systems so that they can catch these types of biases at the beginning stage before they get into production code.&nbsp;</p>



<h4 class="wp-block-heading"><strong>The algorithm is biased because of the lack of diversity in AI which raises more than just a question of fairness and equality, but also a question of quality.&nbsp;</strong></h4>



<p>Diversity in AI has been an ongoing concern among scientists since 2015 <a href="https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/?sh=581a44e4713d">when Google’s Photos app</a> labelled African Americans as gorillas and identified dark-skinned humans as “gorillas” or “chimpanzees.” The African American engineer who was able to identify the problem explained that it was due to faulty algorithms gotten from racist data sets from online websites like Reddit and Twitter where users often submit photos tagged with offensive words like “monkey” or “ape” and other racial slurs. Despite identifying the problem in 2015, nothing was done to solve this problem.</p>



<p>Joy Buolamwinia, a computer scientist and founder of the Algorithmic Justice League, wrote in <em>‘</em><a href="https://time.com/5520558/artificial-intelligence-racial-gender-bias/"><em>Artificial Intelligence Has a Problem With Gender and Racial Bias</em></a><em>’</em> published in Time, about how harmful the bias of artificial intelligence can be to people of colour, especially to women of colour. In 2015, she made a<a href="https://time.com/5520558/artificial-intelligence-racial-gender-bias/">discovery</a>that a particular facial analysis software couldn’t detect her dark-skinned face until she put on a white mask. </p>



<p>She wrote,&nbsp;</p>



<p><em>“These systems are often trained on images of predominantly light-skinned men. And so, I decided to share my experience of the coded gaze, the bias in artificial intelligence that can lead to discriminatory or exclusionary practices.”</em></p>



<p>When women and people of colour are underrepresented in technology, the results shape the data which in turn influences the AI. The consequences of this can be seen everywhere: from voice assistants that don’t understand non-binary genders, to facial recognition software that cannot recognize people with darker skin tones because they were trained on mostly white faces.</p>



<p>The lack of diversity in AI is a direct result of a disproportionate representation of white men within the field, which ultimately impacts how artificial intelligence is developed. Since AI is often trained by humans who undoubtedly have biases, it could result in harmful consequences for people who don’t fit with the current understanding of diversity. For example, if an algorithm is trained with biased data sets, then it will learn those same biases. If these algorithms are used to analyze data sets that contain information about ethnicity or gender identity, they could help to preserve existing stereotypes instead of challenging them.&nbsp;</p>



<h4 class="wp-block-heading"><strong>Just because a tool is tested for bias, which assumes that engineers who are checking for bias actually understand how bias manifests and operates, against one group doesn’t mean it is tested for bias against another type of group.</strong></h4>



<p>Tech is already making important decisions about people’s lives and potentially ruling over which political advertisements they see, how their application to their dream job is screened, how police officers are deployed in their neighbourhood, and even predicting their home’s risk of fire. </p>



<p>This is also true when an algorithm is&nbsp;<a href="https://www.forbes.com/sites/carmenniethammer/2020/03/02/ai-bias-could-put-womens-lives-at-riska-challenge-for-regulators/?sh=ac29c94534f2">considering several types of identity factors</a>&nbsp;at the same time: A tool may be deemed fairly accurate on white women, for instance, but that doesn’t necessarily mean it works with black women.</p>



<p>When people’s lives, livelihoods, and dignity are on the line, AI must be developed with care. Diversity in race will lead to a better AI for everyone. Biased AI will only reinforce existing social inequalities, creating more inequality rather than doing the opposite.</p>



<p>The solution is to have more diverse teams working on building AI. We need more women and people of colour in tech so algorithms that don’t reinforce gender stereotypes or racial biases can be created.&nbsp; To build unbiased AI, we have to create an inclusive society which will in turn decide how our lives will change in AI-dominated environments. AI researchers need to include all communities in their design process from the beginning.</p>
</div><hr class="my-4"/><div class="social-icons flex gap-4 lg:gap-8"><a class="" href="https://twitter.com/intent/tweet?url=&amp;text=Unbiased: How Can AI Be Designed to Be Unbiased Towards Black Women&amp;via=TheStackJournal" target="_blank" title="Twitter share link"><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#B68CFB" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17" stroke="#B68CFB"></circle><g clip-path="url(#a)"><path fill="#B68CFB" d="M24.271 13.925c.011.163.011.325.011.49 0 4.993-3.801 10.752-10.753 10.752v-.003a10.699 10.699 0 0 1-5.793-1.694 7.589 7.589 0 0 0 5.593-1.566 3.784 3.784 0 0 1-3.53-2.625c.566.11 1.15.087 1.706-.065a3.78 3.78 0 0 1-3.032-3.704v-.048a3.756 3.756 0 0 0 1.716.473 3.784 3.784 0 0 1-1.17-5.046 10.726 10.726 0 0 0 7.789 3.948 3.782 3.782 0 0 1 6.44-3.447 7.582 7.582 0 0 0 2.4-.918 3.794 3.794 0 0 1-1.661 2.09 7.516 7.516 0 0 0 2.17-.594 7.676 7.676 0 0 1-1.886 1.957Z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M7.736 8.473h18.421v18.42H7.737z"></path></clipPath></defs></svg></a><a class="" href="https://www.facebook.com/dialog/share?display=popup&amp;href=" target="_blank" title="Facebook share link"><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#B68CFB" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17" stroke="#B68CFB"></circle><g clip-path="url(#a)"><path fill="#B68CFB" d="M26.42 17.21a9.21 9.21 0 1 0-10.649 9.099v-6.436h-2.338V17.21h2.338v-2.029c0-2.308 1.375-3.583 3.48-3.583 1.007 0 2.06.18 2.06.18v2.266h-1.16c-1.145 0-1.502.71-1.502 1.439v1.727h2.555l-.408 2.663H18.65v6.436c4.403-.691 7.77-4.501 7.77-9.099Z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M8 8h18.421v18.421H8z"></path></clipPath></defs></svg></a><a class="" href="https://www.linkedin.com/shareArticle?url=&amp;mini=true&amp;title=Unbiased: How Can AI Be Designed to Be Unbiased Towards Black Women" target="_blank" title="LinkedIn share link"><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#B68CFB" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17" stroke="#B68CFB"></circle><g clip-path="url(#a)"><path fill="#B68CFB" d="M23.432 24.168h-2.73v-4.274c0-1.02-.018-2.331-1.42-2.331-1.42 0-1.638 1.11-1.638 2.257v4.348h-2.73v-8.79h2.62v1.201h.037a2.873 2.873 0 0 1 2.585-1.42c2.767 0 3.277 1.82 3.277 4.187l-.001 4.822Zm-11.597-9.991a1.584 1.584 0 1 1 0-3.168 1.584 1.584 0 0 1 0 3.168Zm1.364 9.991h-2.732v-8.79H13.2v8.79ZM24.792 8.474H9.096a1.344 1.344 0 0 0-1.36 1.328v15.762a1.345 1.345 0 0 0 1.36 1.33h15.696a1.348 1.348 0 0 0 1.365-1.33V9.801a1.347 1.347 0 0 0-1.365-1.328"></path></g><defs><clipPath id="a"><path fill="#fff" d="M7.736 8.473h18.421v18.42H7.737z"></path></clipPath></defs></svg></a><button class=""><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#B68CFB" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17" stroke="#B68CFB"></circle><g clip-path="url(#a)"><path fill="#B68CFB" d="m20.489 15.54 2.519 2.518a4.355 4.355 0 1 1-6.158 6.158l-.839-.84a1.187 1.187 0 1 1 1.678-1.68l.841.84a1.979 1.979 0 0 0 2.799-2.799l-2.52-2.519a1.98 1.98 0 0 0-2.122-.443c-.128.05-.247.103-.36.155l-.367.172c-.49.221-.868.317-1.349-.163-.69-.69-.51-1.328.33-1.908a4.356 4.356 0 0 1 5.548.508ZM15.73 10.78l.84.84a1.188 1.188 0 0 1-1.68 1.68l-.84-.84a1.98 1.98 0 1 0-2.799 2.798l2.52 2.519a1.978 1.978 0 0 0 2.122.443c.128-.05.247-.103.36-.155l.367-.172c.49-.221.869-.316 1.349.163.69.69.511 1.328-.33 1.908a4.356 4.356 0 0 1-5.548-.508l-2.519-2.519a4.355 4.355 0 0 1 4.745-7.114c.53.223 1.01.548 1.413.957Z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M6.791 8h19v19h-19z"></path></clipPath></defs></svg></button><span class="pt-1 italic"></span></div><hr class="my-4"/></div><div class="lg:w-1/4 flex-none"><div class="mb-8 "><h4 class="text-2xl font-semibold my-2">Latest News</h4><hr class="mb-4"/><a class="inline-block text-lg mb-4 hover:underline" href="/posts/startup-spotlight-kola-market">Startup Spotlight – Kola Market</a><a class="inline-block text-lg mb-4 hover:underline" href="/posts/women-in-tech-olajumoke-oduwole">Meet Olajumoke Oduwole: Founder of KJK Africa </a><a class="inline-block text-lg mb-4 hover:underline" href="/posts/rose-margaret-ekeng-itua-has-become-the-first-black-woman-to-hold-a-phd-in-cybernetics">Rose-Margaret Ekeng-Itua has become the first black woman to hold a PhD in Cybernetics</a><a class="inline-block text-lg mb-4 hover:underline" href="/posts/tech-sales-vs-business-development">Tech Sales vs Business Development</a><a class="inline-block text-lg mb-4 hover:underline" href="/posts/the-stack-journal-launches-website-for-women-focused-tech-news">The Stack Journal Launches Website for Women-Focused Tech News.</a></div><div class="bg-amber-100 rounded-2xl text-2xl p-6 my-4"><h3 class="text-xl leading-tight mb-4">Be the first to hear when it drops</h3><form><input type="text" class="w-full my-1 px-4 py-3 text-sm rounded-full border border-purple-500" placeholder="Name"/><input type="text" class="w-full my-1 px-4 py-3 text-sm rounded-full border border-purple-500" placeholder="Email Address"/><button class="w-full text-white text-sm my-4 px-2 py-4 rounded-full bg-purple-800 hover:bg-purple-500">Subscribe</button></form></div><div class="flex flex-wrap gap-1 my-8"><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/awards">Awards</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/dear-tech-sis">Dear Tech Sis</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/essays">Essays</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/events">Events</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/founders">Founders</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/industry-report">Industry Report</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/news">News</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/opportunities">Opportunities</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/startups">Startups</a><a class="capitalize rounded-full border border-black text-black text-xs lg:text-sm px-6 py-3 hover:bg-purple-500 hover:border-purple-500 hover:text-white" href="/category/uncategorized">uncategorized</a></div></div></div></div><footer></footer></article><div class="container mx-auto px-5 lg-px-10"><div class="lg:mx-8"><div class="flex grow justify-center items-center my-12"><div class="grow border-t border-black"></div><h3 class=" text-2xl md:text-3xl mx-8">Related Articles</h3><div class="grow border-t border-black"></div></div><div><section><div class="grid grid-cols-1 lg:grid-cols-3 lg:gap-x-8 gap-y-4"><div class=""> <div class=" flex text-white rounded-[16px] lg:rounded-[30px] bg-top bg-no-repeat bg-cover mb-2" style="background-image:url(https://wp.thestackjournal.com/wp-content/uploads/2024/05/CHIMUANYA_DIKE-scaled.jpg)"><div class="w-full rounded-b-[16px] lg:rounded-b-[30px] bg-gradient-to-t from-black mt-16 lg:mt-48 p-8"><div class="mb-4"><a href="/category/dear-tech-sis"><span style="background-color:rgb(20 184 166);color:#FFF" class="capitalize rounded-full px-6 py-3"> <!-- -->Dear Tech Sis<!-- --> </span></a></div><h3 class="leading-tight h-[5rem] lg:h-[9rem] my-4 lg:my-8 text-xl lg:text-4xl"><a class="hover:underline line-clamp-3" href="/posts/what-does-it-mean-to-be-a-customer-support-manager-insights-from-chimuanya-dike">What Does it Mean to Be a Customer Support Manager? Insights from Chimuanya Dike</a></h3><div style="color:rgb(20 184 166)">By <span class="font-semi-bold">Miracle Okah</span> </div></div></div></div><div class=""> <div class=" flex text-white rounded-[16px] lg:rounded-[30px] bg-top bg-no-repeat bg-cover mb-2" style="background-image:url(https://wp.thestackjournal.com/wp-content/uploads/2024/04/magnet-me-JUpaXbh-Fgc-unsplash-scaled.jpg)"><div class="w-full rounded-b-[16px] lg:rounded-b-[30px] bg-gradient-to-t from-black mt-16 lg:mt-48 p-8"><div class="mb-4"><a href="/category/dear-tech-sis"><span style="background-color:rgb(20 184 166);color:#FFF" class="capitalize rounded-full px-6 py-3"> <!-- -->Dear Tech Sis<!-- --> </span></a></div><h3 class="leading-tight h-[5rem] lg:h-[9rem] my-4 lg:my-8 text-xl lg:text-4xl"><a class="hover:underline line-clamp-3" href="/posts/careers-in-tech-for-women-to-pursue">Careers in Tech for Women to Pursue</a></h3><div style="color:rgb(20 184 166)">By <span class="font-semi-bold">Miracle Okah</span> </div></div></div></div><div class=""> <div class=" flex text-white rounded-[16px] lg:rounded-[30px] bg-top bg-no-repeat bg-cover mb-2" style="background-image:url(https://wp.thestackjournal.com/wp-content/uploads/2024/03/two-business-woman-cafe-scaled.jpg)"><div class="w-full rounded-b-[16px] lg:rounded-b-[30px] bg-gradient-to-t from-black mt-16 lg:mt-48 p-8"><div class="mb-4"><a href="/category/dear-tech-sis"><span style="background-color:rgb(20 184 166);color:#FFF" class="capitalize rounded-full px-6 py-3"> <!-- -->Dear Tech Sis<!-- --> </span></a></div><h3 class="leading-tight h-[5rem] lg:h-[9rem] my-4 lg:my-8 text-xl lg:text-4xl"><a class="hover:underline line-clamp-3" href="/posts/5-influential-women-making-waves-in-the-tech-industry">5 Influential Women Making Waves in the Tech Industry</a></h3><div style="color:rgb(20 184 166)">By <span class="font-semi-bold">Miracle Okah</span> </div></div></div></div></div></section></div></div><hr class="border-accent-2 my-8 lg:my-10"/><div class="flex flex-col lg:w-3/4 text-white rounded-2xl lg:rounded-[42px] bg-center bg-no-repeat bg-cover mt-8 lg:mt-20 mx-auto p-4 lg:py-20" style="background-image:url(https://res.cloudinary.com/do3qitis2/image/upload/q_auto/f_auto/letter-box_kq0gbh)"><div class="lg:w-1/2 mx-auto text-center my-8"><h3 class="leading-snug text-2xl mb-2">Be the first to hear about it</h3><p>Subscribe to The Stack Journal, a free daily newsletter that features the best tech new and everything in betweeen</p></div><div class="lg:w-1/2 lg:mx-auto"><form action="" class="flex flex-col"><input type="email" name="email" placeholder="Enter your email address here" class="bg-transparent text-center border rounded-full py-4 enabled:hover:border-gray-400" value=""/><button disabled="" class="w-48 mx-auto text-center bg-purple-800 hover:bg-purple-500 rounded-full my-4 py-4">Subscribe</button></form></div></div></div><footer class="bg-amber-100 border-t border-accent-2 mt-16 py-16 lg:py-20"><div class="container mx-auto px-5 lg-px-10"><div class="flex flex-col lg:flex-row items-start"><div class="lg:w-1/3 mb-8"><a class="logo inline-block align-middle" href="/"><img alt="" loading="lazy" width="300" height="60" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=384&amp;q=75 1x, /_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=640&amp;q=75 2x" src="/_next/image?url=%2Fimages%2Fthe-stack-journal-logo.png&amp;w=640&amp;q=75"/></a><div class="social-icons flex gap-4 lg:gap-8 mt-8"><a target="_blank" class="" href="https://x.com/TheStackJournal"><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#532D97" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17.5" fill="#532D97"></circle><g clip-path="url(#a)"><path fill="#fff" d="M24.535 13.453c.011.162.011.325.011.489 0 4.993-3.802 10.753-10.753 10.753v-.003A10.7 10.7 0 0 1 8 22.997a7.589 7.589 0 0 0 5.593-1.566 3.784 3.784 0 0 1-3.53-2.624c.566.109 1.15.086 1.706-.066a3.78 3.78 0 0 1-3.032-3.704v-.048a3.756 3.756 0 0 0 1.715.473 3.784 3.784 0 0 1-1.17-5.046 10.729 10.729 0 0 0 7.79 3.948 3.782 3.782 0 0 1 6.44-3.447 7.583 7.583 0 0 0 2.4-.917 3.793 3.793 0 0 1-1.661 2.09 7.513 7.513 0 0 0 2.17-.595 7.68 7.68 0 0 1-1.886 1.958Z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M8 8h18.421v18.421H8z"></path></clipPath></defs></svg></a><a target="_blank" class="" href="https://www.linkedin.com/company/thestackjournal/"><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#532D97" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17.5" fill="#532D97"></circle><g clip-path="url(#a)"><path fill="#fff" d="M23.695 23.696h-2.73V19.42c0-1.019-.017-2.331-1.419-2.331-1.421 0-1.639 1.11-1.639 2.257v4.348h-2.73v-8.79h2.621v1.202h.037a2.871 2.871 0 0 1 2.585-1.42c2.766 0 3.276 1.82 3.276 4.187v4.822Zm-11.597-9.992a1.584 1.584 0 1 1 0-3.168 1.584 1.584 0 0 1 0 3.168Zm1.365 9.992H10.73v-8.79h2.732v8.79ZM25.056 8H9.359A1.344 1.344 0 0 0 8 9.33v15.762a1.345 1.345 0 0 0 1.36 1.33h15.697a1.348 1.348 0 0 0 1.365-1.33V9.328A1.347 1.347 0 0 0 25.056 8"></path></g><defs><clipPath id="a"><path fill="#fff" d="M8 8h18.421v18.421H8z"></path></clipPath></defs></svg></a><a target="_blank" class="" href="https://www.instagram.com/theStackJournal"><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#532D97" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17.5" fill="#532D97"></circle><g clip-path="url(#a)"><path fill="#FD5" d="M22.103 8h-9.786A4.317 4.317 0 0 0 8 12.317v9.786a4.317 4.317 0 0 0 4.317 4.318h9.786a4.317 4.317 0 0 0 4.318-4.318v-9.786A4.317 4.317 0 0 0 22.103 8Z"></path><path fill="#fff" d="M22.103 8h-9.786A4.317 4.317 0 0 0 8 12.317v9.786a4.317 4.317 0 0 0 4.317 4.318h9.786a4.317 4.317 0 0 0 4.318-4.318v-9.786A4.317 4.317 0 0 0 22.103 8Z"></path><path fill="#532D97" d="M17.21 10.016c-1.953 0-2.199.008-2.966.043-.766.035-1.289.156-1.746.334-.474.184-.875.43-1.275.83-.4.4-.646.802-.83 1.275-.18.457-.3.98-.335 1.746-.034.768-.043 1.013-.043 2.967 0 1.955.008 2.2.043 2.967.035.766.157 1.288.334 1.746.184.473.43.875.83 1.275.4.4.802.646 1.275.83.457.178.98.3 1.746.335.768.034 1.013.043 2.967.043 1.954 0 2.199-.009 2.966-.043.767-.036 1.29-.157 1.748-.335a3.52 3.52 0 0 0 1.274-.83c.4-.4.646-.802.83-1.275.177-.457.299-.98.334-1.746.035-.768.044-1.012.044-2.967 0-1.954-.01-2.2-.044-2.967-.035-.766-.157-1.289-.334-1.746a3.532 3.532 0 0 0-.83-1.275c-.4-.4-.8-.646-1.275-.83-.458-.178-.981-.299-1.747-.334-.768-.035-1.012-.043-2.967-.043h.002Zm-.645 1.296h.646c1.921 0 2.149.007 2.908.042.701.032 1.082.149 1.336.248.335.13.575.286.827.538.251.252.407.492.538.827.099.254.216.634.248 1.336.034.758.042.986.042 2.907 0 1.92-.008 2.148-.042 2.906-.032.702-.15 1.083-.248 1.336-.13.336-.287.575-.538.827-.252.252-.491.407-.827.538-.254.099-.635.216-1.336.248-.759.034-.987.042-2.908.042-1.921 0-2.15-.008-2.908-.042-.701-.033-1.082-.15-1.336-.248a2.229 2.229 0 0 1-.827-.538 2.23 2.23 0 0 1-.539-.827c-.098-.254-.216-.635-.248-1.336-.034-.759-.041-.986-.041-2.908s.007-2.148.041-2.907c.032-.701.15-1.082.248-1.336a2.23 2.23 0 0 1 .539-.827 2.23 2.23 0 0 1 .827-.539c.254-.099.635-.216 1.336-.248.664-.03.921-.039 2.262-.04v.001Zm4.487 1.195a.863.863 0 1 0 0 1.727.863.863 0 0 0 0-1.727Zm-3.841 1.009a3.695 3.695 0 1 0 0 7.39 3.695 3.695 0 0 0 0-7.39Zm0 1.297a2.399 2.399 0 1 1 0 4.797 2.399 2.399 0 0 1 0-4.797Z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M8 8h18.421v18.421H8z"></path></clipPath></defs></svg></a><a target="_blank" class="" href="https://web.facebook.com/profile.php?id=100077432629714"><svg xmlns="http://www.w3.org/2000/svg" width="35" height="35" fill="none" color="#532D97" class="hover:opacity-75"><circle cx="17.5" cy="17.5" r="17.5" fill="#532D97"></circle><g clip-path="url(#a)"><path fill="#fff" d="M26.42 17.21a9.21 9.21 0 1 0-10.649 9.099v-6.436h-2.338V17.21h2.338v-2.029c0-2.308 1.375-3.583 3.48-3.583 1.007 0 2.06.18 2.06.18v2.266h-1.16c-1.145 0-1.502.71-1.502 1.439v1.727h2.555l-.408 2.663H18.65v6.436c4.403-.691 7.77-4.501 7.77-9.099Z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M8 8h18.421v18.421H8z"></path></clipPath></defs></svg></a></div></div><div class="lg:w-1/3 sm:flex gap-12 xl:gap-20"><ul class="mb-8"><li class="text-lg font-bold mb-4">Company</li><li class="mb-4"><a href="/about" class="hover:text-purple-800">About Us</a></li><li class="mb-4"><a href="/contact" class="hover:text-purple-800">Contact</a></li><li class="mb-4"><a href="/category/events" class="hover:text-purple-800">Events</a></li><li class="mb-4"><a href="/careers" class="hover:text-purple-800">Careers</a></li></ul><ul class="mb-8"><li class="text-lg font-bold mb-4">Tags</li><li class="mb-4"><a href="/tag/ai" class="hover:text-purple-800">AI</a></li><li class="mb-4"><a href="/tag/fintech" class="hover:text-purple-800">Fintech</a></li><li class="mb-4"><a href="/tag/venture-capital" class="hover:text-purple-800">Venture Capital</a></li><li class="mb-4"><a href="/tag/startup" class="hover:text-purple-800">Startup</a></li><li class="mb-4"><a href="/tag/ecommerce" class="hover:text-purple-800">Ecommerce</a></li></ul><ul class="mb-8"><li class="text-lg font-bold mb-4">Legal</li><li class="mb-4"><a href="/privacy" class="hover:text-purple-800">Privacy</a></li></ul></div><div class="lg:ml-auto"><form action="" class="flex__ flex-col item-end__ lg:w-[350px] lg:h-[300px] lg:text-right"><h4 class="text-2xl mb-4">Join our community</h4><p class="">Get first access to Opportunities, Resources, Industry Reports &amp; more.</p><input type="text" name="name" placeholder="Name" class="w-full my-1 p-4 bg-transparent border-b border-gray-800"/><input type="email" name="email" placeholder="Eamil Addres" class="w-full my-1 p-4 bg-transparent border-b border-gray-800"/><button class="bg-purple-800 text-white hover:bg-purple-500 rounded-full px-8 py-4 my-8 ml-auto">Join the waiting list</button></form></div></div></div></footer></main></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"preview":false,"post":{"title":"Unbiased: How Can AI Be Designed to Be Unbiased Towards Black Women","excerpt":"\u003cp\u003eArtificial Intelligence (AI) has become even more popular in recent years. Governmental bodies, large organizations, and small online businesses are all using AI to make smart business decisions. \u003c/p\u003e\n","slug":"unbiased-how-can-ai-be-designed-to-be-unbiased-towards-black-women","date":"2022-06-11T12:00:00","featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/03/oc0413wkhxjg7dbcnpnk.jpeg"}},"author":{"node":{"name":"Iyanuoluwa Adenle","firstName":"Iyanuoluwa","lastName":"Adenle","avatar":{"url":"https://secure.gravatar.com/avatar/aeeddafd589107b66a58882d645c7bd5?s=96\u0026d=mm\u0026r=g"}}},"categories":{"edges":[{"node":{"name":"Dear Tech Sis","slug":"dear-tech-sis","categoryId":3}}]},"tags":{"edges":[{"node":{"name":"AI"}},{"node":{"name":"Tech"}}]},"content":"\n\u003cp\u003eArtificial Intelligence (AI) has become even more popular in recent years. Governmental bodies, large organizations, and small online businesses are all using AI to make smart business decisions. AI is a type of technology that enables computers to learn on their own, without being programmed with the help of advanced algorithms.\u0026nbsp;\u003c/p\u003e\n\n\n\n\u003cp\u003ePeople often assume that AI is neutral, except they aren’t. The problem with AI today is the algorithm. By design, algorithms are built using past data sets in order to learn from them. If the past was biased towards white males, then this will lead to biased results. This is known as ‘algorithmic bias’ or ‘machine learning bias’. Algorithms can be trained on an inherently limited set of data, and this means that the gender and race gap in the data sets mess with the algorithms. Machines learn the data that it is being fed and if the data recommended to the machine is already biased, AI can be programmed to be racist, sexist or prejudiced.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen we factor in\u0026nbsp;\u003ca href=\"https://time.com/5520558/artificial-intelligence-racial-gender-bias/\"\u003eracial and gender bias\u003c/a\u003e\u0026nbsp;that is being recommended into the systems, therefore influencing the algorithms, it becomes clear that because the people aren’t diverse enough in their thinking and tastes, our algorithms are biased as well. It is important that the problem is fixed by having diverse teams building these kinds of systems so that they can catch these types of biases at the beginning stage before they get into production code.\u0026nbsp;\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003e\u003cstrong\u003eThe algorithm is biased because of the lack of diversity in AI which raises more than just a question of fairness and equality, but also a question of quality.\u0026nbsp;\u003c/strong\u003e\u003c/h4\u003e\n\n\n\n\u003cp\u003eDiversity in AI has been an ongoing concern among scientists since 2015 \u003ca href=\"https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/?sh=581a44e4713d\"\u003ewhen Google’s Photos app\u003c/a\u003e labelled African Americans as gorillas and identified dark-skinned humans as “gorillas” or “chimpanzees.” The African American engineer who was able to identify the problem explained that it was due to faulty algorithms gotten from racist data sets from online websites like Reddit and Twitter where users often submit photos tagged with offensive words like “monkey” or “ape” and other racial slurs. Despite identifying the problem in 2015, nothing was done to solve this problem.\u003c/p\u003e\n\n\n\n\u003cp\u003eJoy Buolamwinia, a computer scientist and founder of the Algorithmic Justice League, wrote in \u003cem\u003e‘\u003c/em\u003e\u003ca href=\"https://time.com/5520558/artificial-intelligence-racial-gender-bias/\"\u003e\u003cem\u003eArtificial Intelligence Has a Problem With Gender and Racial Bias\u003c/em\u003e\u003c/a\u003e\u003cem\u003e’\u003c/em\u003e published in Time, about how harmful the bias of artificial intelligence can be to people of colour, especially to women of colour. In 2015, she made a\u003ca href=\"https://time.com/5520558/artificial-intelligence-racial-gender-bias/\"\u003ediscovery\u003c/a\u003ethat a particular facial analysis software couldn’t detect her dark-skinned face until she put on a white mask. \u003c/p\u003e\n\n\n\n\u003cp\u003eShe wrote,\u0026nbsp;\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e“These systems are often trained on images of predominantly light-skinned men. And so, I decided to share my experience of the coded gaze, the bias in artificial intelligence that can lead to discriminatory or exclusionary practices.”\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen women and people of colour are underrepresented in technology, the results shape the data which in turn influences the AI. The consequences of this can be seen everywhere: from voice assistants that don’t understand non-binary genders, to facial recognition software that cannot recognize people with darker skin tones because they were trained on mostly white faces.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe lack of diversity in AI is a direct result of a disproportionate representation of white men within the field, which ultimately impacts how artificial intelligence is developed. Since AI is often trained by humans who undoubtedly have biases, it could result in harmful consequences for people who don’t fit with the current understanding of diversity. For example, if an algorithm is trained with biased data sets, then it will learn those same biases. If these algorithms are used to analyze data sets that contain information about ethnicity or gender identity, they could help to preserve existing stereotypes instead of challenging them.\u0026nbsp;\u003c/p\u003e\n\n\n\n\u003ch4 class=\"wp-block-heading\"\u003e\u003cstrong\u003eJust because a tool is tested for bias, which assumes that engineers who are checking for bias actually understand how bias manifests and operates, against one group doesn’t mean it is tested for bias against another type of group.\u003c/strong\u003e\u003c/h4\u003e\n\n\n\n\u003cp\u003eTech is already making important decisions about people’s lives and potentially ruling over which political advertisements they see, how their application to their dream job is screened, how police officers are deployed in their neighbourhood, and even predicting their home’s risk of fire. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis is also true when an algorithm is\u0026nbsp;\u003ca href=\"https://www.forbes.com/sites/carmenniethammer/2020/03/02/ai-bias-could-put-womens-lives-at-riska-challenge-for-regulators/?sh=ac29c94534f2\"\u003econsidering several types of identity factors\u003c/a\u003e\u0026nbsp;at the same time: A tool may be deemed fairly accurate on white women, for instance, but that doesn’t necessarily mean it works with black women.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen people’s lives, livelihoods, and dignity are on the line, AI must be developed with care. Diversity in race will lead to a better AI for everyone. Biased AI will only reinforce existing social inequalities, creating more inequality rather than doing the opposite.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe solution is to have more diverse teams working on building AI. We need more women and people of colour in tech so algorithms that don’t reinforce gender stereotypes or racial biases can be created.\u0026nbsp; To build unbiased AI, we have to create an inclusive society which will in turn decide how our lives will change in AI-dominated environments. AI researchers need to include all communities in their design process from the beginning.\u003c/p\u003e\n"},"posts":{"edges":[{"node":{"title":"What Does it Mean to Be a Customer Support Manager? Insights from Chimuanya Dike","excerpt":"\u003cp\u003eCustomer support plays an important role in the tech industry, especially in tech companies. It is responsible for helping customers with questions, concerns, and issues related to the company\u0026#8217;s products or services. Customer support professionals speak with their customers via phone, email, chat support, etc. In our tech world today, customer support is often integrated [\u0026hellip;]\u003c/p\u003e\n","slug":"what-does-it-mean-to-be-a-customer-support-manager-insights-from-chimuanya-dike","date":"2024-05-02T09:54:28","categories":{"edges":[{"node":{"name":"Dear Tech Sis","slug":"dear-tech-sis"}}]},"featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/05/CHIMUANYA_DIKE-scaled.jpg"}},"author":{"node":{"name":"Miracle Okah","firstName":"Miracle","lastName":"Okah","avatar":{"url":"https://secure.gravatar.com/avatar/cebae8fde05b50de4eb6952005c1da27?s=96\u0026d=mm\u0026r=g"}}}}},{"node":{"title":"Careers in Tech for Women to Pursue","excerpt":"\u003cp\u003e With access to free online courses, scholarships, and various learning resources, you can learn any tech skill of your choice. \u003c/p\u003e\n","slug":"careers-in-tech-for-women-to-pursue","date":"2024-04-16T13:28:52","categories":{"edges":[{"node":{"name":"Dear Tech Sis","slug":"dear-tech-sis"}}]},"featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/04/magnet-me-JUpaXbh-Fgc-unsplash-scaled.jpg"}},"author":{"node":{"name":"Miracle Okah","firstName":"Miracle","lastName":"Okah","avatar":{"url":"https://secure.gravatar.com/avatar/cebae8fde05b50de4eb6952005c1da27?s=96\u0026d=mm\u0026r=g"}}}}},{"node":{"title":"5 Influential Women Making Waves in the Tech Industry","excerpt":"\u003cp\u003eFemale talent from all across Africa, including Ghana, Kenya, Nigeria, and South Africa, are reshaping the technology narrative.\u003c/p\u003e\n","slug":"5-influential-women-making-waves-in-the-tech-industry","date":"2024-04-02T12:00:00","categories":{"edges":[{"node":{"name":"Dear Tech Sis","slug":"dear-tech-sis"}}]},"featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/03/two-business-woman-cafe-scaled.jpg"}},"author":{"node":{"name":"Miracle Okah","firstName":"Miracle","lastName":"Okah","avatar":{"url":"https://secure.gravatar.com/avatar/cebae8fde05b50de4eb6952005c1da27?s=96\u0026d=mm\u0026r=g"}}}}},{"node":{"title":"Career Change; Transitioning From Law To Tech","excerpt":"\u003cp\u003eIf you’re a woman in tech and would love to share a story, opinion piece, or anything at all with us, shoot us an email at thestackjournal@gmail.com! We’d love to hear from you. \u003c/p\u003e\n","slug":"career-change-transitioning-from-law-to-tech","date":"2024-03-19T12:23:13","categories":{"edges":[{"node":{"name":"Dear Tech Sis","slug":"dear-tech-sis"}}]},"featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/03/pzenelq7yyrhhqsuwyjm.jpg"}},"author":{"node":{"name":"Oluwatobi Afolabi","firstName":"Oluwatobi","lastName":"Afolabi","avatar":{"url":"https://secure.gravatar.com/avatar/8a46aaa3e1f6249d3aac48b14f576580?s=96\u0026d=mm\u0026r=g"}}}}}]},"latest":{"edges":[{"node":{"title":"Startup Spotlight – Kola Market","excerpt":"\u003cp\u003eThey help small and medium-sized businesses to drive sales all year round, increase their profits and grow sustainably.\u003c/p\u003e\n","slug":"startup-spotlight-kola-market","date":"2024-05-08T08:05:38","featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/05/274AC94E-2155-4C6E-9B08-EA8D4977C203.jpg"}},"author":{"node":{"name":"Miracle Okah","firstName":"Miracle","lastName":"Okah","avatar":{"url":"https://secure.gravatar.com/avatar/cebae8fde05b50de4eb6952005c1da27?s=96\u0026d=mm\u0026r=g"}}},"categories":{"edges":[{"node":{"name":"Startups","slug":"startups","categoryId":5}}]},"tags":{"edges":[{"node":{"name":"Female-founder"}},{"node":{"name":"Founder"}},{"node":{"name":"Startup"}}]}}},{"node":{"title":"Meet Olajumoke Oduwole: Founder of KJK Africa ","excerpt":"\u003cp\u003eShe has been trained in entrepreneurship and business management in nine top-notch accelerator programs and enterprise development centres in Africa and Europe.\u003c/p\u003e\n","slug":"women-in-tech-olajumoke-oduwole","date":"2024-05-08T07:58:40","featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/05/EDA185BF-30ED-418A-826C-07B542D1A034.jpg"}},"author":{"node":{"name":"Miracle Okah","firstName":"Miracle","lastName":"Okah","avatar":{"url":"https://secure.gravatar.com/avatar/cebae8fde05b50de4eb6952005c1da27?s=96\u0026d=mm\u0026r=g"}}},"categories":{"edges":[{"node":{"name":"Founders","slug":"founders","categoryId":4}}]},"tags":{"edges":[{"node":{"name":"Female-founder"}},{"node":{"name":"Founder"}},{"node":{"name":"Startup"}}]}}},{"node":{"title":"Rose-Margaret Ekeng-Itua has become the first black woman to hold a PhD in Cybernetics","excerpt":"\u003cp\u003eAn award-winning Nigerian Professor, Rose-Margaret Ekeng-Itua, has emerged as the first black woman in the world to earn a doctorate (PhD) in Cybernetics, which is the scientific study of control and communication in animals and machines, concerned with understanding complex systems like learning, cognition, adaptation, emergence, communication, and efficiency. Rose-Margaret is a pioneering educator, administrator, [\u0026hellip;]\u003c/p\u003e\n","slug":"rose-margaret-ekeng-itua-has-become-the-first-black-woman-to-hold-a-phd-in-cybernetics","date":"2024-05-07T18:05:21","featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/05/IMG_1593.jpg"}},"author":{"node":{"name":"Miracle Okah","firstName":"Miracle","lastName":"Okah","avatar":{"url":"https://secure.gravatar.com/avatar/cebae8fde05b50de4eb6952005c1da27?s=96\u0026d=mm\u0026r=g"}}},"categories":{"edges":[{"node":{"name":"News","slug":"news","categoryId":8}}]},"tags":{"edges":[{"node":{"name":"Cybernetics"}},{"node":{"name":"News"}},{"node":{"name":"Tech"}}]}}},{"node":{"title":"Tech Sales vs Business Development","excerpt":"\u003cp\u003eTech sales and Business development are important for generating revenue for companies in the tech industry. While both of them play the same role of contributing to the company’s growth, they do it in a different way and timeframe. Tech sales focus on closing deals with different customers, while business development creates new business opportunities [\u0026hellip;]\u003c/p\u003e\n","slug":"tech-sales-vs-business-development","date":"2024-05-07T14:56:20","featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/05/joyful-successful-sales-agent-presenting-content-tablet-scaled.jpg"}},"author":{"node":{"name":"Miracle Okah","firstName":"Miracle","lastName":"Okah","avatar":{"url":"https://secure.gravatar.com/avatar/cebae8fde05b50de4eb6952005c1da27?s=96\u0026d=mm\u0026r=g"}}},"categories":{"edges":[{"node":{"name":"Essays","slug":"essays","categoryId":1}}]},"tags":{"edges":[{"node":{"name":"Business Development"}},{"node":{"name":"Sales"}},{"node":{"name":"Tech"}}]}}},{"node":{"title":"The Stack Journal Launches Website for Women-Focused Tech News.","excerpt":"\u003cp\u003eAccording to Kiki Mordi, founder and CEO, The Stack Journal is forging partnerships with women in the tech industry.\u003c/p\u003e\n","slug":"the-stack-journal-launches-website-for-women-focused-tech-news","date":"2024-05-02T09:56:59","featuredImage":{"node":{"sourceUrl":"https://wp.thestackjournal.com/wp-content/uploads/2024/05/96th-TSJ-7229.jpg"}},"author":{"node":{"name":"Kiki Mordi","firstName":"Kiki","lastName":"Mordi","avatar":{"url":"https://secure.gravatar.com/avatar/58f2fe88027e1ca7ef77f058feb3bde2?s=96\u0026d=mm\u0026r=g"}}},"categories":{"edges":[{"node":{"name":"News","slug":"news","categoryId":8}}]},"tags":{"edges":[{"node":{"name":"Female-founder"}},{"node":{"name":"News"}},{"node":{"name":"Tech"}}]}}}]},"categories":{"edges":[{"node":{"name":"Awards","slug":"awards"}},{"node":{"name":"Dear Tech Sis","slug":"dear-tech-sis"}},{"node":{"name":"Essays","slug":"essays"}},{"node":{"name":"Events","slug":"events"}},{"node":{"name":"Founders","slug":"founders"}},{"node":{"name":"Industry Report","slug":"industry-report"}},{"node":{"name":"News","slug":"news"}},{"node":{"name":"Opportunities","slug":"opportunities"}},{"node":{"name":"Startups","slug":"startups"}},{"node":{"name":"uncategorized","slug":"uncategorized"}}]}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"unbiased-how-can-ai-be-designed-to-be-unbiased-towards-black-women"},"buildId":"L5IHP0rbpf_nxdR51peX3","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>